# Activity logs configuration
agent.sources = r_activity
agent.sinks = k_activity
agent.channels = c_activity

# Interceptors
agent.sources.r_activity.interceptors = i_timestamp i_host
agent.sources.r_activity.interceptors.i_timestamp.type = timestamp
agent.sources.r_activity.interceptors.i_host.type = org.apache.flume.interceptor.HostInterceptor$Builder
agent.sources.r_activity.interceptors.i_host.preserveExisting = true
agent.sources.r_activity.interceptors.i_host.hostHeader = hostname

# Source
agent.sources.r_activity.type = spooldir
agent.sources.r_activity.consumeOrder = oldest
agent.sources.r_activity.spoolDir = /opt/airflow/data/logs/activity
agent.sources.r_activity.fileHeader = false
agent.sources.r_activity.basenameHeader = true
agent.sources.r_activity.ignorePattern = ^(?!.*\.json$).*$
agent.sources.r_activity.deletePolicy = never

# Sink
agent.sinks.k_activity.type = hdfs
agent.sinks.k_activity.hdfs.path = hdfs://hadoop-namenode${HDFS_DATA_DIR:-/data}/raw/logs/activity/%Y%m%d
agent.sinks.k_activity.hdfs.filePrefix = activity-%{hostname}-%{timestamp}
agent.sinks.k_activity.hdfs.fileSuffix = .json
agent.sinks.k_activity.hdfs.fileType = DataStream
agent.sinks.k_activity.hdfs.writeFormat = Text
agent.sinks.k_activity.hdfs.minBlockReplicas = 1
agent.sinks.k_activity.hdfs.callTimeout = 10000
agent.sinks.k_activity.hdfs.ipc.client.connect.timeout = 10000
agent.sinks.k_activity.hdfs.useLocalTimeStamp = true
agent.sinks.k_activity.hdfs.batchSize = 15
agent.sinks.k_activity.hdfs.rollInterval = 60
agent.sinks.k_activity.hdfs.idleTimeout = 10
agent.sinks.k_activity.hdfs.batchSize = 100
agent.sinks.k_activity.hdfs.callTimeout = 30000
agent.sinks.k_activity.hdfs.rollSize = 134217728

# Channel
agent.channels.c_activity.type = memory
agent.channels.c_activity.capacity = 10000
agent.channels.c_activity.transactionCapacity = 100

# Binding
agent.sources.r_activity.channels = c_activity
agent.sinks.k_activity.channel = c_activity